{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80000 files belonging to 2 classes.\n",
      "Found 20000 files belonging to 2 classes.\n",
      "Training Classes:\n",
      "['FAKE', 'REAL']\n",
      "Testing Classes:\n",
      "['FAKE', 'REAL']\n"
     ]
    }
   ],
   "source": [
    "img_height = 32\n",
    "img_width = 32\n",
    "batch_size = 500\n",
    "\n",
    "# Load the training data\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"train\",\n",
    "  seed = 512,\n",
    "  image_size = (img_height, img_width),\n",
    "  batch_size = batch_size)\n",
    "\n",
    "# Load the validation data\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"validation\",\n",
    "  seed = 512,\n",
    "  image_size = (img_height, img_width),\n",
    "  batch_size = batch_size)\n",
    "\n",
    "print(\"Training Classes:\")\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "print(\"Testing Classes:\")\n",
    "class_names = val_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ResNet50 pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "include_top=False: Removes the top (classification) layer of ResNet50, leaving only the convolutional layers. This allows the model to act as a feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,136,961\n",
      "Trainable params: 24,079,745\n",
      "Non-trainable params: 57,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the ResNet50 base model without the top layer and with ImageNet weights\n",
    "ResNet_base_model = tf.keras.applications.ResNet50(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet', \n",
    "    input_shape = (img_height, img_width, 3),\n",
    "    pooling = 'max'\n",
    ")\n",
    "\n",
    "# Set ResNet50 layers as trainable\n",
    "ResNet_base_model.trainable = True\n",
    "\n",
    "inputs = keras.Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "# Pass the input through the ResNet50 base model\n",
    "x = ResNet_base_model(inputs, training=False)\n",
    "\n",
    "# Add Batch Normalization\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "\n",
    "x = layers.Dense(\n",
    "    256,\n",
    "    activation=\"relu\",\n",
    "    kernel_regularizer=regularizers.l2(0.01),\n",
    "    activity_regularizer=regularizers.l1(0.01),\n",
    "    bias_regularizer=regularizers.l1(0.01)\n",
    ")(x)\n",
    "\n",
    "x = layers.Dropout(rate=0.4, seed=512)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adamax(learning_rate=0.001),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with Transfer Learning using ResNet50...\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 34s 179ms/step - loss: 2.3834 - accuracy: 0.8934 - precision_1: 0.8918 - recall_1: 0.8954 - val_loss: 1.9111 - val_accuracy: 0.8791 - val_precision_1: 0.8115 - val_recall_1: 0.9877\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 26s 161ms/step - loss: 0.7803 - accuracy: 0.9384 - precision_1: 0.9399 - recall_1: 0.9368 - val_loss: 1.0971 - val_accuracy: 0.8213 - val_precision_1: 0.7377 - val_recall_1: 0.9972\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 27s 162ms/step - loss: 0.3809 - accuracy: 0.9471 - precision_1: 0.9482 - recall_1: 0.9459 - val_loss: 0.3550 - val_accuracy: 0.9463 - val_precision_1: 0.9274 - val_recall_1: 0.9684\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 27s 167ms/step - loss: 0.2331 - accuracy: 0.9554 - precision_1: 0.9555 - recall_1: 0.9554 - val_loss: 0.2889 - val_accuracy: 0.9258 - val_precision_1: 0.8781 - val_recall_1: 0.9887\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 27s 162ms/step - loss: 0.1772 - accuracy: 0.9609 - precision_1: 0.9616 - recall_1: 0.9601 - val_loss: 0.4865 - val_accuracy: 0.8307 - val_precision_1: 0.7478 - val_recall_1: 0.9981\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 27s 163ms/step - loss: 0.1461 - accuracy: 0.9651 - precision_1: 0.9662 - recall_1: 0.9640 - val_loss: 0.3374 - val_accuracy: 0.8773 - val_precision_1: 0.9959 - val_recall_1: 0.7577\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 27s 163ms/step - loss: 0.1240 - accuracy: 0.9707 - precision_1: 0.9706 - recall_1: 0.9707 - val_loss: 0.1850 - val_accuracy: 0.9464 - val_precision_1: 0.9822 - val_recall_1: 0.9093\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 27s 165ms/step - loss: 0.1084 - accuracy: 0.9759 - precision_1: 0.9767 - recall_1: 0.9751 - val_loss: 0.2301 - val_accuracy: 0.9368 - val_precision_1: 0.8982 - val_recall_1: 0.9853\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 27s 163ms/step - loss: 0.0952 - accuracy: 0.9783 - precision_1: 0.9787 - recall_1: 0.9779 - val_loss: 0.1699 - val_accuracy: 0.9481 - val_precision_1: 0.9237 - val_recall_1: 0.9769\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 27s 163ms/step - loss: 0.0839 - accuracy: 0.9820 - precision_1: 0.9820 - recall_1: 0.9821 - val_loss: 0.2629 - val_accuracy: 0.9312 - val_precision_1: 0.9862 - val_recall_1: 0.8745\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 26s 162ms/step - loss: 0.0752 - accuracy: 0.9838 - precision_1: 0.9840 - recall_1: 0.9836 - val_loss: 0.5968 - val_accuracy: 0.8339 - val_precision_1: 0.9984 - val_recall_1: 0.6690\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 27s 164ms/step - loss: 0.0657 - accuracy: 0.9867 - precision_1: 0.9867 - recall_1: 0.9867 - val_loss: 0.1871 - val_accuracy: 0.9521 - val_precision_1: 0.9737 - val_recall_1: 0.9293\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 26s 161ms/step - loss: 0.0546 - accuracy: 0.9900 - precision_1: 0.9902 - recall_1: 0.9898 - val_loss: 0.1521 - val_accuracy: 0.9567 - val_precision_1: 0.9557 - val_recall_1: 0.9579\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 27s 163ms/step - loss: 0.0526 - accuracy: 0.9905 - precision_1: 0.9908 - recall_1: 0.9903 - val_loss: 0.1815 - val_accuracy: 0.9546 - val_precision_1: 0.9627 - val_recall_1: 0.9457\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 27s 162ms/step - loss: 0.0492 - accuracy: 0.9911 - precision_1: 0.9914 - recall_1: 0.9907 - val_loss: 0.1874 - val_accuracy: 0.9524 - val_precision_1: 0.9709 - val_recall_1: 0.9328\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 27s 162ms/step - loss: 0.0448 - accuracy: 0.9922 - precision_1: 0.9922 - recall_1: 0.9922 - val_loss: 0.1739 - val_accuracy: 0.9554 - val_precision_1: 0.9460 - val_recall_1: 0.9661\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 26s 159ms/step - loss: 0.0423 - accuracy: 0.9931 - precision_1: 0.9929 - recall_1: 0.9933 - val_loss: 0.2849 - val_accuracy: 0.9384 - val_precision_1: 0.9824 - val_recall_1: 0.8927\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 27s 162ms/step - loss: 0.0380 - accuracy: 0.9935 - precision_1: 0.9935 - recall_1: 0.9934 - val_loss: 0.2353 - val_accuracy: 0.9459 - val_precision_1: 0.9832 - val_recall_1: 0.9073\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 26s 160ms/step - loss: 0.0381 - accuracy: 0.9934 - precision_1: 0.9934 - recall_1: 0.9935 - val_loss: 0.1720 - val_accuracy: 0.9570 - val_precision_1: 0.9714 - val_recall_1: 0.9416\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 27s 163ms/step - loss: 0.0332 - accuracy: 0.9952 - precision_1: 0.9952 - recall_1: 0.9954 - val_loss: 0.1786 - val_accuracy: 0.9580 - val_precision_1: 0.9567 - val_recall_1: 0.9594\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 26s 160ms/step - loss: 0.0306 - accuracy: 0.9953 - precision_1: 0.9953 - recall_1: 0.9953 - val_loss: 0.1745 - val_accuracy: 0.9555 - val_precision_1: 0.9522 - val_recall_1: 0.9591\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 27s 164ms/step - loss: 0.0280 - accuracy: 0.9962 - precision_1: 0.9960 - recall_1: 0.9964 - val_loss: 0.1609 - val_accuracy: 0.9580 - val_precision_1: 0.9583 - val_recall_1: 0.9577\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 26s 161ms/step - loss: 0.0310 - accuracy: 0.9950 - precision_1: 0.9949 - recall_1: 0.9951 - val_loss: 0.3094 - val_accuracy: 0.9446 - val_precision_1: 0.9800 - val_recall_1: 0.9078\n",
      "Transfer Learning training finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training with Transfer Learning using ResNet50...\")\n",
    "ResNet_model_history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs = 100,\n",
    "    verbose = 1,\n",
    "    callbacks = [early_stopping]\n",
    ")\n",
    "print(\"Transfer Learning training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "40/40 [==============================] - 4s 67ms/step - loss: 0.1685 - accuracy: 0.9538 - precision_1: 0.9523 - recall_1: 0.9553\n",
      "Val Loss: 0.1685\n",
      "Val Accuracy: 0.9538\n",
      "Val Precision: 0.9523\n",
      "Val Recall: 0.9553\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"test\",\n",
    "  seed = 512,\n",
    "  image_size = (img_height, img_width),\n",
    "  batch_size = batch_size)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "val_loss, val_accuracy, val_precision, val_recall = model.evaluate(test_ds)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Val Loss: {val_loss:.4f}\")\n",
    "print(f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Val Precision: {val_precision:.4f}\")\n",
    "print(f\"Val Recall: {val_recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
